{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and setting the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/alliesaizan/Documents/Memos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the memos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the Republican memo\n",
    "f = open(\"nunes_memo.txt\", mode = \"r\", encoding = \"utf-8\")\n",
    "\n",
    "repub_memo = f.readlines()\n",
    "\n",
    "f.close()\n",
    "\n",
    "# Read in the Democrat memo\n",
    "f = open(\"dems_memo.txt\", mode = \"r\", encoding = \"utf-8\")\n",
    "dems_memo = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the memo text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join every sentence in the memos to one string\n",
    "\n",
    "# Republicans\n",
    "repub_memo2 = \"\".join([i for i in repub_memo])\n",
    "repub_memo2\n",
    "\n",
    "# Democrats\n",
    "dems_memo2 = \"\".join([i for i in dems_memo])\n",
    "dems_memo2\n",
    "\n",
    "del repub_memo, dems_memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word_tokenize\n",
    "repub_memo_tokenized = RegexpTokenizer(r'\\w+').tokenize(repub_memo2)\n",
    "repub_memo_tokenized= [i.lower() for i in repub_memo_tokenized if i.lower() not in stopwords.words(\"english\") and len(i) > 1]\n",
    "\n",
    "dems_memo_tokenized = RegexpTokenizer(r'\\w+').tokenize(dems_memo2)\n",
    "dems_memo_tokenized = [i.lower() for i in dems_memo_tokenized if i.lower() not in stopwords.words(\"english\") and len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull in stopwords-removed memos into one document\n",
    "documents = [\" \".join([i for i in repub_memo_tokenized]), \" \".join([i for i in dems_memo_tokenized])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequencies in each memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce word frequencies\n",
    "repub_frequencies = FreqDist(repub_memo_tokenized).most_common(20)\n",
    "dem_frequencies = FreqDist(dems_memo_tokenized).most_common(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the word frequencies from both memos into one Data Frame\n",
    "frequencies1 = pd.DataFrame(repub_frequencies, columns = [\"frequent_words\", \"word_frequency\"])\n",
    "frequencies1['party'] = \"Republican\"\n",
    "\n",
    "frequencies2 = pd.DataFrame(dem_frequencies, columns = [\"frequent_words\", \"word_frequency\"])\n",
    "frequencies2['party'] = \"Democrat\"\n",
    "\n",
    "frequencies = frequencies1.append(frequencies2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the TF-IDF vector\n",
    "tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=RegexpTokenizer(r'\\w+').tokenize)\n",
    "tfidf_representation = tfidf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a dense matric from the TF-IDF matrix (it's currently sparse)\n",
    "dense = tfidf_representation.todense()[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the dense matrix to find common phrases across memos\n",
    "temp_dict = {}\n",
    "\n",
    "phrase_scores = [pair for pair in zip(range(0, len(dense)), dense) if pair[1] > 0]\n",
    "sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(tfidf.get_feature_names()[word_id], score) for (word_id, score) in sorted_phrase_scores][:20]:\n",
    "    print('{0: <20} {1}'.format(phrase, score))\n",
    "    temp_dict[phrase] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the data to CSV for Tableau plotting\n",
    "results = pd.DataFrame(list(temp_dict.items()), columns = ['tfidf_words', 'tfidf_freq'])\n",
    "results.to_csv(\"tfidf.csv\")\n",
    "frequencies.to_csv(\"word_frequencies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
